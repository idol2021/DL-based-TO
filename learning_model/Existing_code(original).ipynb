{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is available')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Stores data on CPU and lets DataLoader move to device.\n",
    "    FC: (N, H, W, C_in)\n",
    "    DTO: (N, H, W, 1)\n",
    "    com: (N,) scalar compliance targets per sample\n",
    "    \"\"\"\n",
    "    def __init__(self,FC,DTO,com):\n",
    "        self.x_data = torch.cuda.FloatTensor(FC)\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) #\n",
    "\n",
    "        self.y_data = torch.cuda.FloatTensor(DTO)\n",
    "        self.y_data = self.y_data.permute(0,3,1,2)\n",
    "\n",
    "        self.z_data = torch.cuda.FloatTensor(com)\n",
    "        \n",
    "        self.len = self.y_data.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index], self.z_data[index]\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4,32,2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32,32,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64,64,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128,128,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128,256,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256,256,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384,128,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128,128,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(192,64,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64,64,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(96,32,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32,32,3,padding=\"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer8 =  nn.Sequential(\n",
    "             nn.Conv2d(32,1,3,padding=\"same\"),\n",
    "             nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x = self.layer4(x3)\n",
    "        x = torch.cat([x,x3],dim=1)\n",
    "        x = self.layer5(x)\n",
    "        x = torch.cat([x,x2],dim=1)\n",
    "        x = self.layer6(x)\n",
    "        x = torch.cat([x,x1],dim=1)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        return x\n",
    "\n",
    "def plot_loss(trn_loss_list,val_loss_list,title='Total Loss',save='Pytorch Total Loss & test.png'):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.plot(trn_loss_list)\n",
    "    plt.plot(val_loss_list)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    plt.rc('font', size=40)\n",
    "    plt.rc('axes', labelsize=50)\n",
    "    plt.rc('xtick', labelsize=40)\n",
    "    plt.rc('ytick', labelsize=40)\n",
    "    plt.rc('legend', fontsize=30)\n",
    "    plt.rc('figure', titlesize=200)\n",
    "    plt.savefig(save)\n",
    "    \n",
    "def topNN(DTO_data_path, FC_data_path, com_data_path, save_path, num_epochs = 200, data_num = 2000,\n",
    "          lamda1 = 5*10**(-15),lamda2 = 10**(-5),mini_batch_size=128):\n",
    "    \n",
    "    # data load\n",
    "    DTO = np.load(DTO_data_path)[0:data_num,:,:,:]\n",
    "    FC = np.load(FC_data_path)[0:data_num,:,:,:]\n",
    "    com = np.load(com_data_path)[0:data_num]\n",
    "\n",
    "    # data split \n",
    "    DTO_train, DTO_test, com_train, com_test, FC_train, FC_test = \\\n",
    "                train_test_split(DTO,com,FC, test_size=0.2, shuffle=True)\n",
    "    DTO_train, DTO_val, com_train, com_val, FC_train, FC_val = \\\n",
    "                train_test_split(DTO_train,com_train,FC_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "    tr_dataset = CustomDataset(FC_train,DTO_train,com_train)\n",
    "    val_dataset = CustomDataset(FC_val,DTO_val,com_val)\n",
    "    test_dataset = CustomDataset(FC_test,DTO_test,com_test)\n",
    "    \n",
    "    tr_dataloader = DataLoader(tr_dataset, batch_size = mini_batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size = mini_batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=True)\n",
    "\n",
    "    cnn = CNN().to(device) # model \n",
    "\n",
    "    loss_fun = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), \n",
    "                                 lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "    os.makedirs(save_path)\n",
    "    os.chdir(save_path)\n",
    "    \n",
    "    f = open('torch_train_results.txt', 'w')\n",
    "    print('\\nlambda1: ',lamda1, file=f)\n",
    "    print('\\nlambda2: ',lamda2, file=f)\n",
    "    print('\\nbatch_size: ', mini_batch_size, file=f)\n",
    "\n",
    "    trn_loss_list = []\n",
    "    train_loss_list = []\n",
    "    train_comploss_list = []\n",
    "    train_conloss_list = []\n",
    "    \n",
    "    val_loss_list = []\n",
    "    vali_loss_list = []\n",
    "    vali_comploss_list = []\n",
    "    vali_conloss_list = []\n",
    "    \n",
    "    trigger_times = 0\n",
    "    patience = 10\n",
    "    start_time = time.time()\n",
    "    print(\"Start\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        trn_loss = 0.0\n",
    "        cnn.train()\n",
    "\n",
    "        for i, samples in enumerate(tr_dataloader):\n",
    "            x_train, y_train, z_train = samples\n",
    "            y_train.requires_grad=True\n",
    "            optimizer.zero_grad()\n",
    "            output = cnn.forward(x_train)\n",
    "            \n",
    "            loss = loss_fun(output,y_train)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for j, val in enumerate(val_dataloader):\n",
    "                x_val, y_val, z_val = val\n",
    "                val_output = cnn(x_val)\n",
    "\n",
    "                v_loss = loss_fun(val_output,y_val)\n",
    "                \n",
    "                val_loss += v_loss\n",
    "\n",
    "            print((\"epoch: {}/{} \\ntrain: | loss: {:.4f} | \\nvalid: | loss: {:.4f} \") .format(epoch+1,num_epochs,loss.item(),v_loss.item()))\n",
    "            trn_loss_list.append(loss.item())\n",
    "            val_loss_list.append(v_loss.item())\n",
    "            \n",
    "    \n",
    "        # Early Stopping criterion patence\n",
    "        if epoch>1:\n",
    "            if val_loss_list[epoch]>val_loss_list[epoch-1]:\n",
    "                trigger_times +=1\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping! {}'.format(epoch+1))\n",
    "                    break\n",
    "            else:\n",
    "                trigger_times = 0\n",
    "        torch.save(cnn, 'model'+str(epoch)+'.pt') \n",
    "    print(\"End\")\n",
    "    print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "\n",
    "    print('\\nTotal iteration: {}/{}'.format(epoch+1, num_epochs), file=f)\n",
    "    print('\\nTraining time: {:.4f}sec'.format((time.time() - start_time)), file=f)\n",
    "    \n",
    "    plot_loss(trn_loss_list,val_loss_list,'Total Loss','Pytorch Total Loss & test1.png')\n",
    "    plot_loss(train_loss_list,vali_loss_list,'BCE Loss','Pytorch BCE Loss & test.png')\n",
    "    plot_loss(train_comploss_list,vali_comploss_list,'comp Loss','Pytorch comp Loss & test.png')\n",
    "    plot_loss(train_conloss_list,vali_conloss_list,'con Loss','Pytorch con Loss & test.png')\n",
    "    plot_loss(trn_loss_list,val_loss_list,'Total Loss','Pytorch Total Loss & test.png')\n",
    "\n",
    "    test_loss_fun = nn.L1Loss() \n",
    "\n",
    "    cnn.eval()\n",
    "    start_time = time.time()\n",
    "    print(\"Start\")\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_comploss = 0.0\n",
    "    test_conloss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, samples in enumerate(test_dataloader):\n",
    "            x_test, y_test, z_test = samples\n",
    "            test_output = cnn(x_test)\n",
    "            test_loss += test_loss_fun(test_output,y_test)\n",
    "\n",
    "            if i == 0: \n",
    "                test_out = test_output\n",
    "                x_test_out = x_test\n",
    "                y_test_out = y_test\n",
    "                z_test_out = z_test\n",
    "            else:\n",
    "                test_out = torch.cat([test_out,test_output], dim=0)\n",
    "                x_test_out = torch.cat([x_test_out,x_test], dim=0)\n",
    "                y_test_out = torch.cat([y_test_out,y_test], dim=0)\n",
    "                z_test_out = torch.cat([z_test_out,z_test], dim=0)\n",
    "\n",
    "    print(\"End\")\n",
    "    print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "    print(\"test loss: {:.4f} \".format(test_loss/(i+1)))\n",
    "    print(\"\\noriginal test loss: {:.4f} \".format(test_loss/(i+1)), file=f)\n",
    "    \n",
    "    accuracy_test = abs(test_out - y_test_out)\n",
    "    accuracy_test = accuracy_test.cpu().numpy()\n",
    "    acc = len(accuracy_test[np.where(accuracy_test<0.5)])/test_out.cpu().numpy().size*100\n",
    "    print(acc, file=f)\n",
    "\n",
    "    save_test = test_out\n",
    "    save_test = save_test.permute(0,2,3,1)\n",
    "    save_test = save_test.detach().cpu().numpy()\n",
    "\n",
    "    save_x_test = x_test_out\n",
    "    save_x_test = save_x_test.permute(0,2,3,1)\n",
    "    save_x_test = save_x_test.detach().cpu().numpy()\n",
    "\n",
    "    save_y_test = y_test_out\n",
    "    save_y_test = save_y_test.permute(0,2,3,1)\n",
    "    save_y_test = save_y_test.detach().cpu().numpy()\n",
    "\n",
    "    save_z_test = z_test_out\n",
    "    save_z_test = save_z_test.detach().cpu().numpy()\n",
    "\n",
    "    np.save('save_new_test.npy',save_test)\n",
    "    np.save('save_x_new_test.npy',save_x_test)\n",
    "    np.save('save_y_new_test.npy',save_y_test)\n",
    "    np.save('save_z_new_test.npy',save_z_test)\n",
    "\n",
    "    torch.save(cnn, 'model.pt')  # save the model \n",
    "    torch.save(cnn.state_dict(), 'model_state_dict.pt')  # save the state_dict of the model\n",
    "    torch.save({\n",
    "        'model': cnn.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }, 'all.tar')  \n",
    "    f.close()\n",
    "    return test_loss/(i+1), test_comploss/(i+1), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_comploss = []\n",
    "test_acc = []\n",
    "\n",
    "epoch = 200\n",
    "data_num = 2000\n",
    "batch_size = 32\n",
    "\n",
    "DTO_data_path = 'newDTO_3232_cantilver_beam_20k.npy'\n",
    "com_data_path = 'newcomp_3232_cantilver_beam_20k.npy'\n",
    "FC_data_path = 'newFCv_3232_cantilver_beam_20k.npy'\n",
    "\n",
    "save_path = 'C:\\\\Users\\\\user\\\\'\n",
    "\n",
    "name = \"2000data_32x32_original_additional_test\"\n",
    "a = topNN(DTO_data_path, FC_data_path, com_data_path,\n",
    "          save_path+name,\n",
    "          epoch,data_num, 10**(-5), 10**(-4), batch_size)\n",
    "\n",
    "test_loss.append(a[0])\n",
    "test_comploss.append(a[1])\n",
    "test_acc.append(a[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
